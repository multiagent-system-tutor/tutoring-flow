# MLLM (Vision-Language Model) Dataset

This directory contains the dataset for Multimodal LLM experiments.

## Structure
- Images requiring visual understanding.
- Prompts/Queries related to the images.
- Expected responses/answers.

## Purpose
Used for testing Vision-Language Models (like GPT-4o, Gemini, LLaVA) in understanding educational content from images.
