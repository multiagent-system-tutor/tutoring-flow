{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c91e1ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'birdapp (Python 3.10.18)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\User\\mamba\\envs\\birdapp ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Eksperimen 11: OCR Pipeline (PaddleOCR + Qwen 2.5)\n",
    "# \n",
    "# This notebook implements the full pipeline for Experiment 4 using PaddleOCR for text extraction and Qwen 2.5 (3B Instruct) for text correction/refinement.\n",
    "# \n",
    "# **Key Improvements:**\n",
    "# - Robust Ollama response parsing.\n",
    "# - Incremental CSV saving to prevent data loss.\n",
    "# - Full dataset processing loop.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8424233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def run(cmd):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\"] + cmd)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Skip:\", \" \".join(cmd))\n",
    "\n",
    "print(\"Cleaning conflicting packages...\")\n",
    "\n",
    "packages_to_remove = [\n",
    "    \"paddlepaddle\",\n",
    "    \"paddlepaddle-gpu\",\n",
    "    \"paddleocr\",\n",
    "    \"albumentations\"\n",
    "]\n",
    "\n",
    "for pkg in packages_to_remove:\n",
    "    run([\"uninstall\", \"-y\", pkg])\n",
    "\n",
    "print(\"Installing stable versions...\")\n",
    "\n",
    "# Paddle stable for PPOCRv4\n",
    "run([\"install\", \"paddlepaddle==2.5.2\"])\n",
    "\n",
    "# PaddleOCR compatible version\n",
    "run([\"install\", \"paddleocr==2.7.0\"])\n",
    "\n",
    "# Other dependencies\n",
    "run([\n",
    "    \"install\",\n",
    "    \"opencv-python\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"lmdb\",\n",
    "    \"albumentations==1.3.1\",\n",
    "    \"ollama\"\n",
    "])\n",
    "\n",
    "print(\"Installation finished.\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from paddleocr import PaddleOCR\n",
    "import paddle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = r'f:\\projek dosen\\tutoring\\Agentic Multimodal Tutor - SLL\\playwithOCR\\dataset\\train'\n",
    "TEST_DIR = r'f:\\projek dosen\\tutoring\\Agentic Multimodal Tutor - SLL\\playwithOCR\\dataset\\test'\n",
    "\n",
    "# Used for Interface/Testing Loop\n",
    "IMAGES_DIR = os.path.join(TEST_DIR, 'images')\n",
    "GT_DIR = os.path.join(TEST_DIR, 'gt')\n",
    "\n",
    "# Fine-tuning Output Directory\n",
    "FINETUNE_MODEL_DIR = r'output/rec_finetune/best_model'\n",
    "\n",
    "# ===================== LIMIT PROCESSING =====================\n",
    "USE_LIMIT = True  # Set to True to limit the number of processed files\n",
    "LIMIT_COUNT = 50   # Number of files to process if limit is active\n",
    "\n",
    "# ### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7048117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def calculate_cer(reference, hypothesis):\n",
    "    if not reference:\n",
    "        return 0.0\n",
    "    ref = \" \".join(reference.split())\n",
    "    hyp = \" \".join(hypothesis.split())\n",
    "    return levenshtein_distance(ref, hyp) / len(ref)\n",
    "\n",
    "\n",
    "# ### GROUND TRUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8451b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ground_truth(filename_base):\n",
    "    path = os.path.join(GT_DIR, f\"{filename_base}.txt\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read().strip()\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# ### DATASET PREPARATION FOR FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ad4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_labels(base_dir, output_file, mode='train'):\n",
    "    \"\"\"Generates PaddleOCR label file from gt folder.\"\"\"\n",
    "    img_dir = os.path.join(base_dir, 'images')\n",
    "    gt_dir = os.path.join(base_dir, 'gt')\n",
    "    \n",
    "    if not os.path.exists(img_dir) or not os.path.exists(gt_dir):\n",
    "        print(f\"[{mode.upper()}] Directory missing: {img_dir} or {gt_dir}\")\n",
    "        return\n",
    "        \n",
    "    labels = []\n",
    "    valid_count = 0\n",
    "    \n",
    "    # Supported extensions\n",
    "    exts = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    images = []\n",
    "    for ext in exts:\n",
    "        images.extend(glob.glob(os.path.join(img_dir, ext)))\n",
    "        \n",
    "    for img_path in images:\n",
    "        filename = os.path.basename(img_path)\n",
    "        # Assumes GT file has same basename + .txt\n",
    "        basename = os.path.splitext(filename)[0]\n",
    "        gt_path = os.path.join(gt_dir, basename + '.txt')\n",
    "        \n",
    "        if os.path.exists(gt_path):\n",
    "            with open(gt_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().strip()\n",
    "            \n",
    "            # Flatten text for simple Rec training\n",
    "            text_flat = text.replace('\\n', ' ')\n",
    "            \n",
    "            # PaddleOCR expects tab separation\n",
    "            labels.append(f\"{img_path}\\t{text_flat}\")\n",
    "            valid_count += 1\n",
    "            \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(labels))\n",
    "        \n",
    "    print(f\"[{mode.upper()}] Generated {output_file} with {valid_count} samples.\")\n",
    "\n",
    "# Create dataset directory for list files\n",
    "os.makedirs('dataset_lists', exist_ok=True)\n",
    "\n",
    "# Prepare Train and Test Lists\n",
    "prepare_dataset_labels(TRAIN_DIR, 'dataset_lists/rec_gt_train.txt', mode='train')\n",
    "prepare_dataset_labels(TEST_DIR, 'dataset_lists/rec_gt_test.txt', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90eade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "print(paddle.__version__)\n",
    "print(paddle.device.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af0676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Fungsi untuk menjalankan Fine-Tuning PaddleOCR via Python\n",
    "def run_finetuning(config_path, pretrain_path, save_dir='output/rec_finetune'):\n",
    "    # Path ke repo PaddleOCR (Assuming standard location relative to inputs or hardcoded)\n",
    "    paddleocr_repo = r\"f:\\projek dosen\\tutoring\\PaddleOCR\" \n",
    "    train_script = os.path.join(paddleocr_repo, \"tools\", \"train.py\")\n",
    "    \n",
    "    # Cek apakah config dan script training ada\n",
    "    if not os.path.exists(config_path):\n",
    "        print(f\"Error: Config file tidak ditemukan di {config_path}\")\n",
    "        return\n",
    "    if not os.path.exists(train_script):\n",
    "        print(f\"Error: Training script tidak ditemukan di {train_script}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[INFO] Menggunakan Config: {config_path}\")\n",
    "    print(f\"[INFO] Pretrained Model: {pretrain_path}\")\n",
    "    print(f\"[INFO] Training Script: {train_script}\")\n",
    "\n",
    "    # Set PYTHONPATH agar bisa import modul dari repo PaddleOCR\n",
    "    env = os.environ.copy()\n",
    "    env[\"PYTHONPATH\"] = paddleocr_repo + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "\n",
    "    # Susun command argumen\n",
    "    cmd = [\n",
    "        sys.executable, train_script,\n",
    "        \"-c\", config_path,\n",
    "        \"-o\",\n",
    "        f\"Global.pretrained_model={pretrain_path}\",\n",
    "        f\"Global.save_model_dir={save_dir}\",\n",
    "        \"Train.dataset.data_dir=./\",\n",
    "        \"Train.dataset.label_file_list=['dataset_lists/rec_gt_train.txt']\", \n",
    "        \"Eval.dataset.data_dir=./\",\n",
    "        \"Eval.dataset.label_file_list=['dataset_lists/rec_gt_test.txt']\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Memulai Fine-tuning... (Output akan muncul di bawah)\")\n",
    "    print(f\"Command Eksekusi: {' '.join(cmd)}\\n\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Eksekusi process dengan streaming output\n",
    "    try:\n",
    "        # bufsize=1 means line buffered\n",
    "        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, env=env)\n",
    "        \n",
    "        # Baca output baris per baris\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            print(line, end='')\n",
    "            \n",
    "        process.stdout.close()\n",
    "        process.wait()\n",
    "        \n",
    "        if process.returncode == 0:\n",
    "             print(\"\\n\" + \"=\"*50)\n",
    "             print(\"[SUCCESS] Fine-tuning Berhasil! Model tersimpan di\", save_dir)\n",
    "             print(\"=\"*50)\n",
    "        else:\n",
    "             print(f\"\\n[FAILURE] Training gagal dengan exit code {process.returncode}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal menjalankan training: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURASI PATH (WAJIB DIISI)\n",
    "# ==========================================\n",
    "# Masukkan Absolute Path ke file .yml config kamu\n",
    "# Contoh: r\"F:\\projek dosen\\tutoring\\...\\Configs\\en_PP-OCRv4_rec.yml\"\n",
    "CONFIG_PATH = r\"f:\\projek dosen\\tutoring\\PaddleOCR\\configs\\rec\\PP-OCRv4\\en_PP-OCRv4_mobile_rec.yml\"\n",
    "\n",
    "# Masukkan Absolute Path ke folder pretrain model kamu\n",
    "# Contoh: r\"F:\\projek dosen\\tutoring\\...\\Pretrain\\en_PP-OCRv4_rec_train\\best_accuracy\"\n",
    "PRETRAIN_PATH = r\"f:\\projek dosen\\tutoring\\PaddleOCR\\pretrain_models\\en_PP-OCRv4_mobile_rec_pretrained.pdparams\"\n",
    "\n",
    "# Jalankan (Uncomment baris di bawah ini setelah path diisi)\n",
    "run_finetuning(CONFIG_PATH, PRETRAIN_PATH)\n",
    "\n",
    "\n",
    "# ### OCR INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing PaddleOCR...\")\n",
    "\n",
    "# Check if Fine-tuned model exists\n",
    "use_model_dir = None\n",
    "if os.path.exists(FINETUNE_MODEL_DIR):\n",
    "    print(f\"\\033[92mFound Fine-tuned Model at {FINETUNE_MODEL_DIR}. Using it!\\033[0m\")\n",
    "    use_model_dir = FINETUNE_MODEL_DIR\n",
    "    # To use SPECIFICALLY the fine-tuned REC model:\n",
    "    ocr = PaddleOCR(rec_model_dir=use_model_dir, \n",
    "                    lang=\"en\", \n",
    "                    enable_mkldnn=False, \n",
    "                    use_angle_cls=True)\n",
    "else:\n",
    "    print(\"\\033[93mFine-tuned model NOT found. Using Default Pre-trained Model.\\033[0m\")\n",
    "    ocr = PaddleOCR(lang=\"en\", enable_mkldnn=False, use_angle_cls=True)\n",
    "\n",
    "\n",
    "# ### LLM CALL (AMAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54675e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== LLM CALL (ROBUST) =====================\n",
    "def run_llm(prompt):\n",
    "    # Run subprocess with robust encoding handling\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", \"qwen2.5:3b-instruct\"],\n",
    "            input=prompt,\n",
    "            text=True,\n",
    "            capture_output=True,\n",
    "            encoding='utf-8',       # Ensure UTF-8 for I/O\n",
    "            errors='replace'        # Replace chars that fail to encode/decode (fixes charmap error)\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            print(f\"  [LLM ERROR] Exit Code: {result.returncode}\")\n",
    "            print(f\"  [LLM STDERR] {result.stderr[:200]}...\") # Print part of stderr\n",
    "            return None\n",
    "            \n",
    "        return result.stdout.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"  [LLM EXCEPTION] {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ### FILE LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = (\n",
    "    glob.glob(os.path.join(IMAGES_DIR, \"*.jpg\")) +\n",
    "    glob.glob(os.path.join(IMAGES_DIR, \"*.png\")) +\n",
    "    glob.glob(os.path.join(IMAGES_DIR, \"*.jpeg\"))\n",
    ")\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# Apply Limit if Enabled\n",
    "if USE_LIMIT and LIMIT_COUNT > 0:\n",
    "    print(f\"Limiting processing to first {LIMIT_COUNT} images.\")\n",
    "    image_files = image_files[:LIMIT_COUNT]\n",
    "\n",
    "print(f\"Found {len(image_files)} images.\")\n",
    "\n",
    "\n",
    "# ### MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image_path in enumerate(image_files):\n",
    "    filename = os.path.basename(image_path)\n",
    "    filename_base = os.path.splitext(filename)[0]\n",
    "    gt_text = read_ground_truth(filename_base)\n",
    "\n",
    "    print(f\"\\nProcessing [{idx+1}/{len(image_files)}]: {filename}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ---------- OCR ----------\n",
    "    ocr_result = ocr.predict(image_path)\n",
    "    extracted_lines = []\n",
    "    bboxes = []\n",
    "\n",
    "    if ocr_result and len(ocr_result) > 0:\n",
    "        if isinstance(ocr_result[0], dict) and \"rec_texts\" in ocr_result[0]:\n",
    "            extracted_lines = ocr_result[0][\"rec_texts\"]\n",
    "            if \"dt_polys\" in ocr_result[0]:\n",
    "                bboxes = ocr_result[0][\"dt_polys\"]\n",
    "        elif isinstance(ocr_result[0], list):\n",
    "            for line in ocr_result[0]:\n",
    "                if isinstance(line, list) and len(line) >= 2:\n",
    "                    if isinstance(line[1], (tuple, list)):\n",
    "                        extracted_lines.append(line[1][0])\n",
    "                    if isinstance(line[0], list):\n",
    "                        bboxes.append(line[0])\n",
    "\n",
    "    raw_text = \"\\n\".join(extracted_lines)\n",
    "\n",
    "    # ---------- VISUALIZATION & BBOX ----------\n",
    "    if bboxes:\n",
    "        img_vis = cv2.imread(image_path)\n",
    "        if img_vis is not None:\n",
    "            img_vis = cv2.cvtColor(img_vis, cv2.COLOR_BGR2RGB)\n",
    "            for box in bboxes:\n",
    "                box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(img_vis, [box], True, (255, 0, 0), 2)\n",
    "            \n",
    "            # Save Image\n",
    "            os.makedirs(r'results/bbox', exist_ok=True)\n",
    "            vis_path = os.path.join(r'results/bbox', f'vis_{filename}')\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(img_vis)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(vis_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            # Save Coords TXT\n",
    "            txt_path = os.path.join(r'results/bbox', f'bbox_{filename_base}.txt')\n",
    "            with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "                for i, box in enumerate(bboxes):\n",
    "                    text = extracted_lines[i] if i < len(extracted_lines) else ''\n",
    "                    f.write(f'{box} | {text}\\n')\n",
    "\n",
    "    # ---------- LLM ----------\n",
    "    final_text = raw_text\n",
    "\n",
    "    if raw_text.strip():\n",
    "        if not os.path.exists(\"prompt_correction.txt\"):\n",
    "            print(\"  [ERROR] prompt_correction.txt not found!\")\n",
    "            continue\n",
    "        with open(\"prompt_correction.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            prompt = f.read().replace(\"{OCR_TEXT}\", raw_text)\n",
    "\n",
    "        print(\"  [LLM] running...\")\n",
    "        llm_out = run_llm(prompt)\n",
    "\n",
    "        if llm_out is None:\n",
    "            print(\"  [LLM] timeout -> skip\")\n",
    "            final_text = raw_text\n",
    "        else:\n",
    "            final_text = (\n",
    "                llm_out\n",
    "                .replace(\"```plaintext\", \"\")\n",
    "                .replace(\"```\", \"\")\n",
    "                .strip()\n",
    "            )\n",
    "            print(\"  [LLM] done\")\n",
    "\n",
    "    # ---------- METRIC ----------\n",
    "    elapsed = time.time() - start_time\n",
    "    cer_raw = calculate_cer(gt_text, raw_text)\n",
    "    cer_refined = calculate_cer(gt_text, final_text)\n",
    "\n",
    "    print(\n",
    "        f\"  OCR Length: {len(raw_text)} | \"\n",
    "        f\"CER Raw: {cer_raw:.2%} | \"\n",
    "        f\"CER Refined: {cer_refined:.2%} | \"\n",
    "        f\"Time: {elapsed:.2f}s\"\n",
    "    )\n",
    "\n",
    "    results.append({\n",
    "        \"filename\": filename,\n",
    "        \"time\": elapsed,\n",
    "        \"cer_raw\": cer_raw,\n",
    "        \"cer_refined\": cer_refined,\n",
    "        \"raw_text\": raw_text,\n",
    "        \"final_text\": final_text,\n",
    "        \"ground_truth\": gt_text\n",
    "    })\n",
    "\n",
    "    # Save partial results incrementally\n",
    "    if len(results) > 0:\n",
    "        pd.DataFrame(results).to_csv('results/exp4_results.csv', index=False)\n",
    "\n",
    "print(\"\\nDONE. Total processed:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad7c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== VISUALIZE METRICS =====================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(f\"Average Time: {df['time'].mean():.4f}s\")\n",
    "    print(f\"Average CER (Raw): {df['cer_raw'].mean():.2%}\")\n",
    "    print(f\"Average CER (Refined): {df['cer_refined'].mean():.2%}\")\n",
    "    \n",
    "    try:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        # Melt for seaborn\n",
    "        df_melted = df.melt(id_vars=['filename'], value_vars=['cer_raw', 'cer_refined'], var_name='Stage', value_name='CER')\n",
    "        \n",
    "        sns.barplot(data=df_melted, x='filename', y='CER', hue='Stage', palette='viridis')\n",
    "        plt.title('Comparison of CER: Raw OCR vs Qwen 2.5 Refinement')\n",
    "        plt.xlabel('Filename')\n",
    "        plt.ylabel('Character Error Rate (0.0 - 1.0)')\n",
    "        # Too many x-labels might clutter, maybe strip?\n",
    "        if len(df) > 20:\n",
    "            plt.xticks([]) # Hide x labels if too many\n",
    "        else:\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_path = 'results/cer_comparison.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Graph saved to {save_path}\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
