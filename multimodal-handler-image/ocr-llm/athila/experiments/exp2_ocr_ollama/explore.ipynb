{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen 2: OCR Pipeline (PaddleOCR + LLM)\n",
    "\n",
    "## Objective\n",
    "Mengimplementasikan pipeline OCR + LLM dengan output terstandar, pengukuran waktu inferensi, dan perhitungan matriks evaluasi (CER).\n",
    "\n",
    "- **Stage 1 (OCR):** PaddleOCR untuk ekstraksi teks.\n",
    "- **Stage 2 (LLM):** Ollama (LLaVA) untuk structuring/refining.\n",
    "- **Metrics:** Inference Time, Character Error Rate (CER).\n",
    "\n",
    "## Output Format\n",
    "```python\n",
    "{\n",
    "    'time': float,      # Detik\n",
    "    'text': str,        # Hasil akhir (JSON/Text)\n",
    "    'image': np.array   # Citra input (optional visualization)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projekdosen\\tutoring\\tutoring-flow\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import ollama\n",
    "from paddleocr import PaddleOCR\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Utility: Character Error Rate (CER) Calculation ---\n",
    "def levenshtein_distance(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def calculate_cer(reference, hypothesis):\n",
    "    if not reference:\n",
    "        return 0.0\n",
    "    # Remove extra whitespaces for fairer comparison\n",
    "    ref = \" \".join(reference.split())\n",
    "    hyp = \" \".join(hypothesis.split())\n",
    "    dist = levenshtein_distance(ref, hyp)\n",
    "    return dist / len(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip show paddleocr\n",
    "### 1. Setup & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PaddleOCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NUC\\AppData\\Local\\Temp\\ipykernel_27132\\939784524.py:4: DeprecationWarning: The parameter `use_angle_cls` has been deprecated and will be removed in the future. Please use `use_textline_orientation` instead.\n",
      "  ocr = PaddleOCR(lang='en', enable_mkldnn=False, use_angle_cls=True)\n",
      "c:\\projekdosen\\tutoring\\tutoring-flow\\.venv\\Lib\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:712: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_doc_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\NUC\\.paddlex\\official_models\\PP-LCNet_x1_0_doc_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('UVDoc', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\NUC\\.paddlex\\official_models\\UVDoc`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-LCNet_x1_0_textline_ori', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\NUC\\.paddlex\\official_models\\PP-LCNet_x1_0_textline_ori`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\NUC\\.paddlex\\official_models\\PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('en_PP-OCRv5_mobile_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `C:\\Users\\NUC\\.paddlex\\official_models\\en_PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dir: c:\\projekdosen\\tutoring\\Agentic Multimodal Tutor - SLL\\playwithOCR\\dataset\\test\n"
     ]
    }
   ],
   "source": [
    "# Init OCR Engine (Load Model)\n",
    "print(\"Initializing PaddleOCR...\")\n",
    "# enable_mkldnn=False prevents Windows-specific AVX crashes\n",
    "ocr = PaddleOCR(lang='en', enable_mkldnn=False, use_angle_cls=True)\n",
    "\n",
    "# Setup Path\n",
    "import glob\n",
    "DATASET_DIR = r'c:\\projekdosen\\tutoring\\Agentic Multimodal Tutor - SLL\\playwithOCR\\dataset\\test'\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, 'images')\n",
    "GT_DIR = os.path.join(DATASET_DIR, 'gt')\n",
    "print(f\"Dataset Dir: {DATASET_DIR}\")\n",
    "\n",
    "# --- GROUND TRUTH UTILITY ---\n",
    "def read_ground_truth(filename_base):\n",
    "    gt_path = os.path.join(GT_DIR, f\"{filename_base}.txt\")\n",
    "    if os.path.exists(gt_path):\n",
    "        with open(gt_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read().strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pipeline Execution (Timed)\n",
    "\n",
    "**Prompting Technique:**  \n",
    "Kami menggunakan **Zero-Shot Instruction Prompting**. Prompt dirancang untuk memberikan instruksi langsung kepada model (LLaVA) agar mengubah input teks mentah menjadi format JSON spesifik tanpa memberikan contoh (shot) sebelumnya.\n",
    "\n",
    "**Prompt:**\n",
    "> \"Berikut adalah teks mentah... Tolong rapikan data ini menjadi format JSON yang valid...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 images.\n",
      "\n",
      "Processing: if4908_103012500097_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:32:00,799] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 146 chars | CER: 34.95% | Time: 81.93s\n",
      "\n",
      "Processing: if4908_103012500098_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:32:58,924] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 139 chars | CER: 47.31% | Time: 58.07s\n",
      "\n",
      "Processing: if4908_103012500281_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:34:59,181] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 232 chars | CER: 93.71% | Time: 120.21s\n",
      "\n",
      "Processing: if4908_103012500305_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:35:28,301] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 132 chars | CER: 58.70% | Time: 29.03s\n",
      "\n",
      "Processing: if4908_103012500322_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:37:29,990] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 214 chars | CER: 38.33% | Time: 121.67s\n",
      "\n",
      "Processing: if4908_103012530052_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:38:39,224] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 242 chars | CER: 78.29% | Time: 69.21s\n",
      "\n",
      "Processing: if4910_103012500004_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:39:20,455] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 200 chars | CER: 23.08% | Time: 41.17s\n",
      "\n",
      "Processing: if4911_103012500384_nomor1.jpg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:40:00,648] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 197 chars | CER: 30.60% | Time: 40.18s\n",
      "\n",
      "Processing: if4910_103012500367_nomor1.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:41:08,405] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 309 chars | CER: 25.85% | Time: 67.74s\n",
      "\n",
      "Processing: if4909_103012500132_nomor1.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:43:20,156] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 185 chars | CER: 40.85% | Time: 131.53s\n",
      "\n",
      "Processing: if4909_103012530074_nomor1.jpeg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026-01-14 16:44:48,952] [    INFO] _client.py:1025 - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OCR Length: 94 chars | CER: 69.89% | Time: 88.71s\n"
     ]
    }
   ],
   "source": [
    "image_files = glob.glob(os.path.join(IMAGES_DIR, \"*.jpg\")) + glob.glob(os.path.join(IMAGES_DIR, \"*.png\")) + glob.glob(os.path.join(IMAGES_DIR, \"*.jpeg\"))\n",
    "print(f\"Found {len(image_files)} images.\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Ensure OCR is initialized correctly\n",
    "if 'ocr' not in locals():\n",
    "    ocr = PaddleOCR(lang='en', enable_mkldnn=False, use_angle_cls=True)\n",
    "\n",
    "for image_path in image_files:\n",
    "    filename = os.path.basename(image_path)\n",
    "    filename_base = os.path.splitext(filename)[0]\n",
    "    ground_truth_text = read_ground_truth(filename_base)\n",
    "    print(f\"\\nProcessing: {filename}...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # --- STAGE 1: OCR ---\n",
    "    # Pass path directly to avoid CV2 nuances\n",
    "    ocr_result = ocr.predict(image_path)\n",
    "\n",
    "    extracted_lines = []\n",
    "\n",
    "    if ocr_result and len(ocr_result) > 0:\n",
    "        extracted_lines = ocr_result[0].get(\"rec_texts\", [])\n",
    "\n",
    "    raw_text = \"\\n\".join(extracted_lines)\n",
    "    \n",
    "    # --- STAGE 2: LLM ---\n",
    "    final_text_output = \"\"\n",
    "    if raw_text.strip():\n",
    "        prompt_content = f\"\"\"\n",
    "        Berikut adalah teks mentah hasil OCR:\\n\n",
    "        {raw_text}\\n\n",
    "        \\n\n",
    "        Tersurukturkan teks di atas menjadi format JSON.\\n\n",
    "        Expected Key: 'tasks' (list of objects with 'task_name', 'status', 'notes').\\n\n",
    "        OUTPUT JSON ONLY.\\n\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = ollama.chat(\n",
    "                model='llava',\n",
    "                messages=[{'role': 'user', 'content': prompt_content}]\n",
    "            )\n",
    "            if isinstance(response, dict) and 'message' in response:\n",
    "                final_text_output = response['message']['content']\n",
    "            else:\n",
    "                final_text_output = str(response)\n",
    "        except Exception as e:\n",
    "             print(f\"LLM Error: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    cer_score = calculate_cer(ground_truth_text, raw_text)\n",
    "    print(f\"  OCR Length: {len(raw_text)} chars | CER: {cer_score:.2%} | Time: {inference_time:.2f}s\")\n",
    "    \n",
    "    results.append({\n",
    "        'filename': filename,\n",
    "        'time': inference_time,\n",
    "        'cer': cer_score,\n",
    "        'raw_text': raw_text,\n",
    "        'final_json': final_text_output\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Output & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "Average Time: 77.2224s\n",
      "Average CER: 49.23%\n",
      "\n",
      "Detailed Results exported to 'exp2_results.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== SUMMARY ===\")\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "if not df.empty:\n",
    "    print(f\"Average Time: {df['time'].mean():.4f}s\")\n",
    "    print(f\"Average CER: {df['cer'].mean():.2%}\")\n",
    "    print(\"\\nDetailed Results exported to 'exp2_results.csv'\")\n",
    "    df.to_csv('exp2_results.csv', index=False)\n",
    "else:\n",
    "    print(\"No results to show.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
