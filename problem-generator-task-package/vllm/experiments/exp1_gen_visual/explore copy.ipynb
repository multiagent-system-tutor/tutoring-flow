{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Eksperimen 1: Visual Problem Generation (VLLM)\n",
                "\n",
                "Generate soal visual dengan VLLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Setup VLLM experiment...\n"
                    ]
                }
            ],
            "source": [
                "print(\"Setup VLLM experiment...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'vllm'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'vllm'"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "import json\n",
                "import re\n",
                "import datetime\n",
                "from vllm import LLM, SamplingParams"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using device: cpu\n"
                    ]
                }
            ],
            "source": [
                "MODEL_NAME = \"facebook/opt-125m\" "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_last_json(text: str):\n",
                "    matches = re.findall(r\"\\{[\\s\\S]*\\}\", text)\n",
                "    if not matches:\n",
                "        return None\n",
                "\n",
                "    for cand in reversed(matches):\n",
                "        try:\n",
                "            return json.loads(cand)\n",
                "        except json.JSONDecodeError:\n",
                "            continue\n",
                "    return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_experiment_vllm(plan, date_str):\n",
                "    prompt = f\"\"\"\n",
                "You are an AI teacher and problem generator.\n",
                "\n",
                "Plan: {plan}\n",
                "Date: {date_str}\n",
                "\n",
                "Task:\n",
                "Generate ONE concrete math problem based on the plan.\n",
                "If an image helps understanding, describe the image clearly in the problem text.\n",
                "\n",
                "Rules:\n",
                "- You MUST fill all fields with real content.\n",
                "- Do NOT repeat placeholders or templates.\n",
                "- Output ONLY valid JSON.\n",
                "- No explanation outside JSON.\n",
                "\n",
                "Required JSON format:\n",
                "{{\n",
                "  \"soal\": \"...\",\n",
                "  \"image_description\": \"...\",\n",
                "  \"solution\": \"...\"\n",
                "}}\n",
                "\"\"\"\n",
                "    \n",
                "    sampling_params = SamplingParams(\n",
                "        temperature=0.2,\n",
                "        top_p=0.9,\n",
                "        max_tokens=1024\n",
                "    )\n",
                "\n",
                "    print(f\"Loading model {MODEL_NAME} using vLLM...\")\n",
                "    llm = LLM(model=MODEL_NAME, trust_remote_code=True)\n",
                "\n",
                "    print(\"Starting generation...\")\n",
                "    start_time = time.time()\n",
                "\n",
                "    outputs = llm.generate([prompt], sampling_params)\n",
                "\n",
                "    end_time = time.time()\n",
                "    inference_time = end_time - start_time\n",
                "\n",
                "    result_text = outputs[0].outputs[0].text\n",
                "\n",
                "    print(f\"Inference finished in {inference_time:.4f} seconds.\")\n",
                "    return result_text, inference_time\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting inference (Ollama)...\n",
                        "Inference finished in 9.6474 seconds.\n",
                        "\n",
                        "--- Raw Model Output ---\n",
                        "{\n",
                        "  \"soal\": \"Diberikan persegi dengan sisi panjang 8 cm dan segitiga yang berada di dalamnya, dengan alas 6 cm dan tinggi 8 cm. Hitunglah luas bangun datar gabungan ini!\",\n",
                        "  \"image_description\": \"Gambar sebuah persegi dengan sisi panjang 8 cm, dan di dalamnya terdapat segitiga dengan alas 6 cm dan tinggi 8 cm.\",\n",
                        "  \"solution\": \"Luas persegi = sisi^2 = 8^2 = 64 cm^2. Luas segitiga = (alas * tinggi) / 2 = (6 * 8) / 2 = 24 cm^2. Jadi, luas bangun datar gabungan ini adalah: 64 + 24 = 88 cm^2.\"\n",
                        "}\n",
                        "\n",
                        "--- Parsed JSON ---\n",
                        "{\n",
                        "    \"soal\": \"Diberikan persegi dengan sisi panjang 8 cm dan segitiga yang berada di dalamnya, dengan alas 6 cm dan tinggi 8 cm. Hitunglah luas bangun datar gabungan ini!\",\n",
                        "    \"image_description\": \"Gambar sebuah persegi dengan sisi panjang 8 cm, dan di dalamnya terdapat segitiga dengan alas 6 cm dan tinggi 8 cm.\",\n",
                        "    \"solution\": \"Luas persegi = sisi^2 = 8^2 = 64 cm^2. Luas segitiga = (alas * tinggi) / 2 = (6 * 8) / 2 = 24 cm^2. Jadi, luas bangun datar gabungan ini adalah: 64 + 24 = 88 cm^2.\"\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "plan_input = \"Geometri: Menghitung luas bangun datar gabungan (Persegi dan Segitiga)\"\n",
                "date_input = datetime.date.today().strftime(\"%Y-%m-%d\")\n",
                "\n",
                "try:\n",
                "    result_text, duration = run_experiment_vllm(plan_input, date_input)\n",
                "\n",
                "    print(\"\\n--- Raw Model Output ---\")\n",
                "    print(result_text)\n",
                "\n",
                "    print(\"\\n--- Parsed JSON ---\")\n",
                "    parsed = extract_last_json(result_text)\n",
                "    if parsed:\n",
                "        print(json.dumps(parsed, indent=4, ensure_ascii=False))\n",
                "    else:\n",
                "        print(\"JSON parsing failed, raw text returned.\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Error running vLLM: {e}\")\n",
                "    print(\"Pastikan vLLM dan CUDA tersedia.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
