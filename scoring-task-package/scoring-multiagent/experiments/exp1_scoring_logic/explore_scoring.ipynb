{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Dict, Any\n",
    "\n",
    "# Library AI & Graph\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00be1489",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- DEFINISI STRUKTUR ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mScoringMultiAgent\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mScoringMultiAgent\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mScoringMultiAgent\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: \u001b[43mDict\u001b[49m[\u001b[38;5;28mstr\u001b[39m, Any] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m      4\u001b[39m         \u001b[38;5;28mself\u001b[39m.config = config \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m      5\u001b[39m         \u001b[38;5;66;03m# Bisa ganti model di sini untuk eksperimen (misal: llama3, llama3.2)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "# --- DEFINISI STRUKTUR ---\n",
    "class ScoringMultiAgent:\n",
    "    def __init__(self, config: Dict[str, Any] = None):\n",
    "        self.config = config or {}\n",
    "        # Bisa ganti model di sini untuk eksperimen (misal: llama3, llama3.2)\n",
    "        model_name = self.config.get(\"model\", \"llama3.2\")\n",
    "        \n",
    "        print(f\"ðŸ› ï¸ Initializing Agent with model: {model_name}\")\n",
    "        self.llm = ChatOllama(model=model_name, temperature=0, format=\"json\")\n",
    "        \n",
    "        # Context Miskonsepsi (Bisa diedit-edit di sini untuk cari prompt terbaik)\n",
    "        self.misconceptions_list = \"\"\"\n",
    "        1. Intentional Bug (IB)\n",
    "        2. While Demon (WD)\n",
    "        3. WhileIf / IfWhile\n",
    "        4. Executed Once (EO)\n",
    "        5. Drop Through Error (DT)\n",
    "        6. Infinite Loop\n",
    "        7. Wrong Order\n",
    "        \"\"\"\n",
    "        self.app = self._build_graph()\n",
    "\n",
    "    def _build_graph(self):\n",
    "        # State Definition\n",
    "        class AgentState(TypedDict):\n",
    "            problem: str\n",
    "            solution: str\n",
    "            student_code: str\n",
    "            rubric: str\n",
    "            messages: Annotated[List[BaseMessage], operator.add]\n",
    "            iteration_count: int\n",
    "            final_json: Dict[str, Any]\n",
    "\n",
    "        workflow = StateGraph(AgentState)\n",
    "        workflow.add_node(\"Supervisor\", self._supervisor_node)\n",
    "        workflow.add_node(\"StyleChecker\", self._style_checker_agent)\n",
    "        workflow.add_node(\"LogicChecker\", self._logic_checker_agent)\n",
    "        workflow.set_entry_point(\"Supervisor\")\n",
    "        workflow.add_conditional_edges(\"Supervisor\", self._router, \n",
    "                                     {\"run_workers\": \"StyleChecker\", END: END})\n",
    "        workflow.add_edge(\"StyleChecker\", \"LogicChecker\")\n",
    "        workflow.add_edge(\"LogicChecker\", \"Supervisor\")\n",
    "        return workflow.compile()\n",
    "\n",
    "    # --- NODE FUNCTIONS ---\n",
    "    def _style_checker_agent(self, state):\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a Style Checker.\"),\n",
    "            (\"user\", \"Code:\\n{student_code}\\n\\nReturn JSON with key 'style_analysis'.\")\n",
    "        ])\n",
    "        chain = prompt | self.llm \n",
    "        res = chain.invoke({\"student_code\": state[\"student_code\"]})\n",
    "        return {\"messages\": [HumanMessage(content=f\"Style: {res.content}\")]}\n",
    "\n",
    "    def _logic_checker_agent(self, state):\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"You are a Logic Checker. Check misconceptions:\\n{self.misconceptions_list}\"),\n",
    "            (\"user\", \"Problem: {problem}\\nSolution: {solution}\\nStudent: {student_code}\\n\\nReturn JSON with key 'logic_analysis'.\")\n",
    "        ])\n",
    "        chain = prompt | self.llm\n",
    "        res = chain.invoke({\n",
    "            \"problem\": state[\"problem\"], \"solution\": state[\"solution\"], \n",
    "            \"student_code\": state[\"student_code\"]\n",
    "        })\n",
    "        return {\"messages\": [HumanMessage(content=f\"Logic: {res.content}\")]}\n",
    "\n",
    "    def _supervisor_node(self, state):\n",
    "        current_iter = state.get(\"iteration_count\", 0)\n",
    "        max_iter = self.config.get(\"max_iterations\", 1)\n",
    "        \n",
    "        if current_iter >= max_iter:\n",
    "            final_prompt = f\"\"\"\n",
    "            Generate FINAL JSON.\n",
    "            Format: {{\"score\": \"0-100\", \"correct\": \"true/false\", \"summary\": \"text\", \"Misconceptions\": \"text\"}}\n",
    "            Rubric: {state['rubric']}\n",
    "            Reports: {state['messages']}\n",
    "            \"\"\"\n",
    "            try:\n",
    "                res = self.llm.invoke(final_prompt)\n",
    "                clean_json = res.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                final_dict = json.loads(clean_json)\n",
    "            except:\n",
    "                final_dict = {\"error\": \"JSON Parse Fail\", \"raw\": res.content}\n",
    "            return {\"final_json\": final_dict, \"iteration_count\": current_iter + 1}\n",
    "        \n",
    "        return {\"iteration_count\": current_iter + 1}\n",
    "\n",
    "    def _router(self, state):\n",
    "        if state.get(\"final_json\"): return END\n",
    "        return \"run_workers\"\n",
    "\n",
    "    def run(self, input_data):\n",
    "        start_time = time.time()\n",
    "        initial_state = {\n",
    "            \"problem\": input_data.get(\"problem\", \"\"),\n",
    "            \"solution\": input_data.get(\"solution\", \"\"),\n",
    "            \"student_code\": input_data.get(\"pseudocode\", \"\"),\n",
    "            \"rubric\": input_data.get(\"rubric\", \"\"),\n",
    "            \"messages\": [],\n",
    "            \"iteration_count\": 1\n",
    "        }\n",
    "        try:\n",
    "            output = self.app.invoke(initial_state)\n",
    "            final_json = output.get(\"final_json\", {})\n",
    "            summary_text = f\"Score: {final_json.get('score')}. {final_json.get('summary')}\"\n",
    "        except Exception as e:\n",
    "            final_json = {\"error\": str(e)}\n",
    "            summary_text = \"Error.\"\n",
    "            \n",
    "        return {\n",
    "            'time': time.time() - start_time,\n",
    "            'text': summary_text,\n",
    "            'data': final_json\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Konfigurasi\n",
    "config = {\n",
    "    \"model\": \"llama3.2\", # Coba ganti ke 'llama3' kalau mau bandingin hasil\n",
    "    \"max_iterations\": 1\n",
    "}\n",
    "\n",
    "# 2. Inisialisasi\n",
    "scorer = ScoringMultiAgent(config)\n",
    "\n",
    "# 3. Test Case: Infinite Loop\n",
    "inputs_fail = {\n",
    "    \"pseudocode\": \"x=1; WHILE x<5 DO; PRINT x; ENDWHILE\", \n",
    "    \"problem\": \"Cetak angka 1-5\",\n",
    "    \"solution\": \"i=1; WHILE i<=5 DO; PRINT i; i=i+1; ENDWHILE\",\n",
    "    \"rubric\": \"Benar=100\"\n",
    "}\n",
    "\n",
    "# 4. Jalankan\n",
    "print(\"â³ Sedang menilai...\")\n",
    "result = scorer.run(inputs_fail)\n",
    "\n",
    "# 5. Tampilkan Hasil\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"â±ï¸ Waktu: {result['time']:.4f} detik\")\n",
    "print(\"=\"*40)\n",
    "print(\"ðŸ“ Summary Text:\", result['text'])\n",
    "print(\"ðŸ“Š Data JSON:\", json.dumps(result['data'], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
